# ğŸ“„ Gemma 4B + Ollama + AnythingLLM Kurulum ve Entegrasyon SÃ¼reci

Bu belge, Ollama Ã¼zerinden indirilen `gemma3:4b` modelinin local olarak nasÄ±l Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nÄ± ve AnythingLLM ile nasÄ±l entegre edildiÄŸini adÄ±m adÄ±m aÃ§Ä±klamaktadÄ±r. AmaÃ§, local bir LLMâ€™in nasÄ±l serve edildiÄŸini ve AnythingLLM'in bu LLM ile nasÄ±l iletiÅŸim kurduÄŸunu teknik dÃ¼zeyde gÃ¶stermektir.

---

## ğŸ”¹ 1. LLM Kurulumu (Ollama ile)

### Ollama'nÄ±n Kurulumu  
Sistemime uygun Ollama kurulum paketi resmÃ® web sitesinden indirildi ve yÃ¼klendi. YÃ¼kleme sonrasÄ± terminalden doÄŸrulama yapÄ±ldÄ±:

**ollama --version** komutu ile test edildi.

**ollama run gemma3:4b** Bu komut LLM local olarak varsa Ã§alÄ±ÅŸtÄ±rÄ±yor aksi takdirde bu LLM'i kuruyor.Bu komutla model http://localhost:11434 Ã¼zerinden HTTP API olarak Ã§alÄ±ÅŸmaya baÅŸladÄ±. Bu endpoint Ã¼zerinden yapÄ±lan her istek modele iletilir ve yanÄ±t dÃ¶nÃ¼lÃ¼r.

- Not: Ollama, modeli local olarak serve eder. DÄ±ÅŸ bir servise ihtiyaÃ§ duymadan kendi kendine Ã§alÄ±ÅŸÄ±r.

## ğŸ”¹ 2. Anything LLM Kurulumu

- AnythingLLM GitHub sayfasÄ±ndan indirildi. Sistem gereksinimleri karÅŸÄ±landÄ±ktan sonra uygulama baÅŸlatÄ±ldÄ± ve tarayÄ±cÄ± Ã¼zerinden arayÃ¼z aÃ§Ä±ldÄ±.

- Uygulama Ã¼zerinden `settings` kÄ±smÄ±ndan LLM provider olarak Ollama seÃ§ildi. Local olarak kurulu olan Gemma3:4b seÃ§ildi. Bu ayarlarla Anything LLM Ollama'da Ã§alÄ±ÅŸan modeli kullanmaya baÅŸladÄ±.

## â“ SÄ±k Sorulan Sorulara YanÄ±tlar

**LLMâ€™i nereden serve ediyorsun?**

â†’ Ollama Ã¼zerinden http://localhost:11434 adresinden serve ediyorum.

**AnythingLLM kendi iÃ§inde mi model Ã§alÄ±ÅŸtÄ±rÄ±yor?**

â†’ HayÄ±r. Modeli Ã§alÄ±ÅŸtÄ±ran Ollama. AnythingLLM sadece arayÃ¼z ve yÃ¶nlendirme katmanÄ±dÄ±r.

**3rd party LLM servisi kullandÄ±n mÄ±?**

â†’ HayÄ±r. Her ÅŸey local olarak Ã§alÄ±ÅŸÄ±yor. DÄ±ÅŸ baÄŸlantÄ± yok.


# Semantic Kernel + Ollama ile Lokal Soru-Cevap UygulamasÄ± GeliÅŸtirme SÃ¼reci

## ğŸ“Œ GeliÅŸtirme OrtamÄ±
- Kod GeliÅŸtirme: macOS (MacBook)

- Model Sunucusu: Windows PC (Ollama Ã¼zerinde Gemma 3B)

### KullanÄ±lan Teknolojiler:

- C# (.NET)

- Microsoft Semantic Kernel

- Ollama (Local LLM Ã§alÄ±ÅŸtÄ±rmak iÃ§in)

- Gemma 3B (Ollama Ã¼zerinden indirilen model)

- Basit terminal tabanlÄ± soru-cevap senaryosu


##Â C# ve Semantic Kernel ile Test UygulamasÄ± GeliÅŸtirme
MacBook Ã¼zerinde bir .NET projesi oluÅŸturuldu. AmaÃ§, temel bir soru-cevap etkileÅŸimi saÄŸlamaktÄ±. Microsoft Semantic Kernel frameworkâ€™Ã¼ kullanÄ±larak LLM ile baÄŸlantÄ± saÄŸlayacak bir chat yapÄ±sÄ± kuruldu.

### Kod iÃ§inde ÅŸu adÄ±mlar yer aldÄ±:

- Kernel nesnesi oluÅŸturuldu.

- LLM baÄŸlantÄ±sÄ± iÃ§in HttpClient kullanÄ±ldÄ±.

- KullanÄ±cÄ±nÄ±n giriÅŸ yaptÄ±ÄŸÄ± promptâ€™lar, HTTP Ã¼zerinden LLM'e gÃ¶nderildi.

- DÃ¶nen yanÄ±tlar terminalde gÃ¶sterildi.

## LLM Modelinin Windows Ãœzerinde SunulmasÄ±
LLM modeli olarak Gemma 3B kullanÄ±ldÄ±. Bu model, Windows Ã¼zerinde kurulu olan Ollama platformu aracÄ±lÄ±ÄŸÄ±yla serve edildi.

- Ollama Windows'a kuruldu.

- Terminalden aÅŸaÄŸÄ±daki komutla model indirildi ve Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±:

- ollama run gemma3:4b

Model, varsayÄ±lan olarak yalnÄ±zca localhost:11434 adresinden hizmet veriyordu. Fakat Mac'ten bu modele eriÅŸebilmek iÃ§in aÅŸaÄŸÄ±daki gibi tÃ¼m aÄŸ arabirimlerinden eriÅŸime izin verecek ÅŸekilde Ollama yeniden baÅŸlatÄ±ldÄ±:

- Ortam deÄŸiÅŸkenkerinden OLLAMA_HOST deÄŸiÅŸkeni `0.0.0.0` deÄŸeri ile oluÅŸturuldu.

## Port AÃ§ma ve GÃ¼venlik AyarlarÄ±

Model dÄ±ÅŸarÄ±ya aÃ§Ä±k hale getirilse bile, Windowsâ€™un varsayÄ±lan gÃ¼venlik duvarÄ± politikalarÄ± nedeniyle dÄ±ÅŸ baÄŸlantÄ±lar engellenmiÅŸti. Bu nedenle ÅŸu iÅŸlemler yapÄ±ldÄ±:

### Windows GÃ¼venlik DuvarÄ± > GeliÅŸmiÅŸ Ayarlar > Gelen Kurallar menÃ¼sÃ¼nden:

- 11434 TCP portu iÃ§in Ã¶zel bir inbound kural tanÄ±mlandÄ±.

- Gerekirse firewall kÄ±sa sÃ¼reli olarak devre dÄ±ÅŸÄ± bÄ±rakÄ±ldÄ± (sadece test iÃ§in).

## BaÄŸlantÄ± Testleri
MacBookâ€™tan Windows bilgisayara gerÃ§ekten baÄŸlanÄ±lÄ±p baÄŸlanÄ±lamadÄ±ÄŸÄ±nÄ± test etmek iÃ§in curl komutu kullanÄ±ldÄ±:

- curl http://192.168.1.45:11434/api/generate -d '{"model": "gemma3:4b", "prompt": "Hello, how are you?", "stream": false}'

EÄŸer bu istek baÅŸarÄ±lÄ± bir yanÄ±t dÃ¶nerse, baÄŸlantÄ±nÄ±n doÄŸru ÅŸekilde kurulduÄŸu teyit edildi.

